# Ego4D_EpisodicMemory_Group19

This repository contains code for the **Natural Language Queries (NLQ)** task on egocentric videos from the Ego4D dataset, including extensions for qualitative evaluation using Video-LLaVA and modified variants of VSLNet and VSLBase.


## Notebooks and Dependencies

### 1. `VSLBase_EgoVLP.ipynb` and `VSLBase_Omnivore.ipynb`
- **Dependencies:** all files in `NLQ/VSLBase/`  
- **Purpose:** training and evaluation of VSLBase with EgoVLP or Omnivore features.  
- **Note:** make sure EgoVLP or Omnivore features are downloaded and stored in `/content/ego4d_data/`.

### 2. `VSLNet_Omnivore_and_modified.ipynb` and `VSLNet_EgoVLP_and_modified.ipynb`
- **Dependencies:** all files in `NLQ/VSLNet/`  
- **Purpose:** training and evaluation of modified VSLNet (without HighLightLayer, option for separate encoders for video and text).  
- **Note:** EgoVLP or Omnivore features must be downloaded and placed in `/content/ego4d_data/`.

### 3. `Some_qualitative_results.ipynb` and `Extension2.ipynb`
- **Dependencies:** all files in `NLQ/EXTENSION2/`  
  - `best_prediction.json`: best checkpoint from VSLNet on EgoVLP  
  - `compute_scores.py`: computes ROUGE, BLEU, and METEOR scores  
  - `extract_clips.py`: extracts video clips using ffmpeg  
  - `llava.py`: runs Video-LLaVA  
  - `select_query.py`: selects top 50 queries  
  - `top50_annotated.json`: manually annotated ground truth for top 50 queries
- **Purpose:** generate qualitative results for a subset of queries and evaluate with quantitative metrics.

**Example commands executed in `Extension2.ipynb`:**

```bash
%%bash
python /content/NLQ/EXTENSION2/llava.py \
    --clips_dir "/content/ego4d_data/v1/clips_top50" \
    --queries_json "/content/NLQ/EXTENSION2/top50_queries.json" \
    --output "/content/NLQ/EXTENSION2/answers_video_llava.json"

%%bash
python /content/NLQ/EXTENSION2/compute_scores.py \
    --llava "/content/NLQ/EXTENSION2/answers_video_llava.json" \
    --gt "/content/NLQ/EXTENSION2/top50_annotated.json"

Produced outputs:
answers_video_llava.json: answers generated by Video-LLaVA
ROUGE, BLEU, METEOR metrics computed against manually annotated ground truth.

Important Notes
Ensure all files and folders from the original repositories are present and modified as described (VSLNet_modified.py, VSLBase_modified.py, main_VSLNet_modified.py, main_VSLBase_modified.py).
For EXTENSION2, videos must be properly extracted using extract_clips.py before running Video-LLaVA.
All notebooks require access to the downloaded features to run correctly.
